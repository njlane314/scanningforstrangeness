{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "090b9e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uproot\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2a3110e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['imageanalyser;1', 'imageanalyser/SampleTree;1', 'imageanalyser/ImageTree;1', 'FRH;1', 'FRV;1', 'rICKR;1', 'rICKI;1', 'PreC;1', 'PostC;1', 'PostO;1', 'PreD;1', 'PostDO;1', 'ER;1']\n"
     ]
    }
   ],
   "source": [
    "file_path = \"/gluster/data/dune/niclane/nlane_prod_strange_resample_fhc_run2_fhc_reco2_reco2_trainingimage_background_lambdamuon_ana.root\"  \n",
    "#file_path = \"/gluster/data/dune/niclane/test.root\"\n",
    "\n",
    "root_file = uproot.open(file_path)\n",
    "print(root_file.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d50cfe18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['run', 'subrun', 'event', 'event_type', 'planes', 'width', 'height', 'input_data', 'truth_data']\n"
     ]
    }
   ],
   "source": [
    "tree_name = \"imageanalyser/ImageTree\" \n",
    "tree = root_file[tree_name]\n",
    "\n",
    "print(tree.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0598ffd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ..., 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], ...]\n",
      "Data Type: <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "input_data = tree[\"input_data\"].array(library=\"np\")\n",
    "truth_data = tree[\"truth_data\"].array(library=\"np\")\n",
    "\n",
    "print(\"Shape:\", input_data[1])\n",
    "print(\"Data Type:\", type(input_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d3bc2b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of events: 706\n",
      "Planes per event: 3\n",
      "Pixels per plane: 262144\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of events: {len(input_data)}\")  \n",
    "print(f\"Planes per event: {len(input_data[0])}\")  \n",
    "print(f\"Pixels per plane: {len(input_data[0][0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "530e9d63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'uproot.containers.STLVector'>\n",
      "Number of entries in imageanalyser/ImageTree: 706\n"
     ]
    }
   ],
   "source": [
    "event_index = 2\n",
    "event = input_data[event_index]  \n",
    "truth_event = truth_data[event_index] \n",
    "\n",
    "run_numbers = tree[\"run\"].array(library=\"np\")\n",
    "subrun_numbers = tree[\"subrun\"].array(library=\"np\")\n",
    "event_numbers = tree[\"event\"].array(library=\"np\")\n",
    "\n",
    "event_type = tree[\"event_type\"].array(library=\"np\")\n",
    "\n",
    "print(event_type[event_index])\n",
    "\n",
    "print(type(input_data))\n",
    "plane = event[0]\n",
    "print(type(plane))\n",
    "\n",
    "num_entries = tree.num_entries\n",
    "print(f\"Number of entries in {tree_name}: {num_entries}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "852c01c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "W, H = 512, 512  \n",
    "\n",
    "plane_images = [np.array(list(plane), dtype=np.float32).reshape(H, W) for plane in event]\n",
    "truth_images = [np.array(list(plane), dtype=np.float32).reshape(H, W) for plane in truth_event]\n",
    "\n",
    "plane_labels = [\"U\", \"V\", \"W\"]\n",
    "\n",
    "r, sr, evnum = run_numbers[event_index], subrun_numbers[event_index], event_numbers[event_index]\n",
    "\n",
    "for i, (input_img, truth_img) in enumerate(zip(plane_images, truth_images)):\n",
    "    fig, ax = plt.subplots(figsize=(12, 12), dpi=600)\n",
    "\n",
    "    ax.imshow(input_img,\n",
    "              origin=\"lower\",\n",
    "              cmap=\"jet\",\n",
    "              norm=colors.PowerNorm(gamma=0.35, vmin=input_img.min(), vmax=input_img.max()))\n",
    "\n",
    "    overlay = False\n",
    "    if overlay:\n",
    "        ax.imshow(truth_img, origin=\"lower\", cmap=\"cool\", alpha=0.4)\n",
    "\n",
    "    ax.set_xticks([0, W - 1])\n",
    "    ax.set_yticks([0, H - 1])\n",
    "    ax.tick_params(axis=\"both\", direction=\"out\", length=6, width=1.5, labelsize=18)\n",
    "    ax.set_xlim(0, W - 1)\n",
    "    ax.set_ylim(0, H - 1)\n",
    "    ax.set_xlabel(\"Local Wire Coord\", fontsize=20)\n",
    "    ax.set_ylabel(\"Local Drift Time\", fontsize=20)\n",
    "    ax.set_title(f\"Plane {plane_labels[i]} (Run {r}, Subrun {sr}, Event {evnum})\", fontsize=22)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"event_{r}_{sr}_{evnum}_plane_{plane_labels[i]}.png\")\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c06465db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Event Index: 5\n",
      "Event Type: 1\n",
      "Number of truth image channels: 3\n"
     ]
    }
   ],
   "source": [
    "event_indices = [5]\n",
    "\n",
    "run_numbers = tree[\"run\"].array(library=\"np\")\n",
    "subrun_numbers = tree[\"subrun\"].array(library=\"np\")\n",
    "event_numbers = tree[\"event\"].array(library=\"np\")\n",
    "event_type = tree[\"event_type\"].array(library=\"np\")\n",
    "\n",
    "W, H = 512, 512  \n",
    "plane_labels = [\"U\", \"V\", \"W\"]\n",
    "\n",
    "for event_index in event_indices:\n",
    "    event = input_data[event_index]  \n",
    "    truth_event = truth_data[event_index]  \n",
    "\n",
    "    print(f\"Processing Event Index: {event_index}\")\n",
    "    print(f\"Event Type: {event_type[event_index]}\")\n",
    "\n",
    "    r, sr, evnum = run_numbers[event_index], subrun_numbers[event_index], event_numbers[event_index]\n",
    "\n",
    "    plane_images = [np.array(list(plane), dtype=np.float32).reshape(H, W) for plane in event]\n",
    "    truth_images = [np.array(list(plane), dtype=np.float32).reshape(H, W) for plane in truth_event]\n",
    "\n",
    "    print(f\"Number of truth image channels: {len(truth_images)}\")\n",
    "\n",
    "    for i, (input_img, truth_img) in enumerate(zip(plane_images, truth_images)):\n",
    "        fig, ax = plt.subplots(figsize=(12, 12), dpi=600)\n",
    "\n",
    "        ax.imshow(input_img,\n",
    "                  origin=\"lower\",\n",
    "                  cmap=\"jet\",\n",
    "                  norm=colors.PowerNorm(gamma=0.35, vmin=input_img.min(), vmax=input_img.max()))\n",
    "\n",
    "        overlay = True\n",
    "        if overlay:\n",
    "            ax.imshow(truth_img, origin=\"lower\", cmap=\"cool\", alpha=0.4)\n",
    "\n",
    "        ax.set_xticks([0, W - 1])\n",
    "        ax.set_yticks([0, H - 1])\n",
    "        ax.tick_params(axis=\"both\", direction=\"out\", length=6, width=1.5, labelsize=18)\n",
    "        ax.set_xlim(0, W - 1)\n",
    "        ax.set_ylim(0, H - 1)\n",
    "        ax.set_xlabel(\"Local Wire Coord\", fontsize=20)\n",
    "        ax.set_ylabel(\"Local Drift Time\", fontsize=20)\n",
    "        ax.set_title(f\"Plane {plane_labels[i]} (Run {r}, Subrun {sr}, Event {evnum})\", fontsize=22)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"event_{r}_{sr}_{evnum}_plane_{plane_labels[i]}.png\")\n",
    "        plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f510e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import yaml\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import uproot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from src.config import Config\n",
    "from src.dataset import SegmentationDataset, ContrastiveDataset  \n",
    "from src.visualiser import Visualiser\n",
    "from src.trainers import SegmentationTrainer, ContrastiveTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1823df",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"cfg/default.yaml\"\n",
    "config = Config(path)\n",
    "\n",
    "print(\"Loaded configuration:\")\n",
    "print(config.as_dict())\n",
    "print(\"Dataset File Path:\", config.get(\"dataset.file_path\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d573d4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    segmentation_dataset = SegmentationDataset(config)\n",
    "    print(f\"SegmentationDataset initialized with {len(segmentation_dataset)} samples.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading SegmentationDataset: {e}\")\n",
    "\n",
    "try:\n",
    "    contrastive_dataset = ContrastiveDataset(config)\n",
    "    print(f\"ContrastiveDataset initialized with {len(contrastive_dataset)} samples.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading ContrastiveDataset: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe194a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualiser = Visualiser(segmentation_dataset, width=512, height=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b08bb45",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualiser.visualise_event_planes(idx=10, save=True, show=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62cdac00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from src.config import Config\n",
    "\n",
    "config_path = \"cfg/default.yaml\"  \n",
    "config = Config(config_path)\n",
    "\n",
    "print(\"Training Config:\\n\", yaml.dump(config.as_dict(), default_flow_style=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f2c292",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = SegmentationDataset(config)\n",
    "trainer = SegmentationTrainer(config, dataset)\n",
    "#print(trainer.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e996c273",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a174047d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_checkpoint(checkpoint_path, config):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = UResNet(\n",
    "        in_dim=config.get(\"model.in_channels\"),\n",
    "        n_classes=config.get(\"model.num_classes\"),\n",
    "        n_filters=config.get(\"model.filters\"),\n",
    "        drop_prob=config.get(\"model.dropout\"),\n",
    "        y_range=None\n",
    "    )\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "    model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "def run_inference(model, sample):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    image, truth = sample\n",
    "    image_tensor = image.unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        output = model(image_tensor)\n",
    "    prediction = torch.argmax(output, dim=1).cpu().squeeze(0)\n",
    "    return image, truth, prediction\n",
    "\n",
    "def visualise_prediction(image, truth, prediction, plane, run, subrun, event):\n",
    "    fig, ax = plt.subplots(figsize=(12,12), dpi=600)\n",
    "    norm_img = mcolors.PowerNorm(gamma=0.35, vmin=image.min(), vmax=image.max())\n",
    "    ax.imshow(image, origin=\"lower\", cmap=\"jet\", norm=norm_img)\n",
    "    num_classes = int(np.max(prediction)) + 1\n",
    "    cmap_seg = plt.get_cmap(\"tab10\", num_classes)\n",
    "    boundaries = np.arange(-0.5, num_classes+0.5, 1)\n",
    "    norm_seg = mcolors.BoundaryNorm(boundaries, cmap_seg.N)\n",
    "    ax.imshow(prediction, origin=\"lower\", cmap=cmap_seg, norm=norm_seg, alpha=0.5)\n",
    "    ax.set_xticks([0, image.shape[1]-1])\n",
    "    ax.set_yticks([0, image.shape[0]-1])\n",
    "    ax.tick_params(axis=\"both\", direction=\"out\", length=6, width=1.5, labelsize=18)\n",
    "    ax.set_xlabel(\"Local Wire Coord\", fontsize=20)\n",
    "    ax.set_ylabel(\"Local Drift Time\", fontsize=20)\n",
    "    ax.set_title(f\"Plane {plane} | Run {run}, Subrun {subrun}, Event {event}\", fontsize=22)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"inference_plane_{plane}_run_{run}_subrun_{subrun}_event_{event}.png\")\n",
    "    plt.show()\n",
    "    plt.close(fig)\n",
    "\n",
    "def visualise_model_inference(model, dataset, event_idx):\n",
    "    sample = dataset[event_idx]\n",
    "    image, truth, prediction = run_inference(model, sample)\n",
    "    run, subrun, event = \"Unknown\", \"Unknown\", event_idx\n",
    "    planes = [\"U\", \"V\", \"W\"]\n",
    "    for i, plane in enumerate(planes):\n",
    "        visualise_prediction(image[i], truth[i], prediction[i], plane, run, subrun, event)\n",
    "\n",
    "def plot_loss_curve(epoch_loss_history):\n",
    "    epochs = np.array([e[0] for e in epoch_loss_history])\n",
    "    train_loss = np.array([e[1] for e in epoch_loss_history])\n",
    "    train_err = np.array([e[2] for e in epoch_loss_history])\n",
    "    val_loss = np.array([e[3] for e in epoch_loss_history])\n",
    "    val_err = np.array([e[4] for e in epoch_loss_history])\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.errorbar(epochs, train_loss, yerr=train_err, fmt='-o', capsize=5, label='Train Loss', color='blue', markerfacecolor='white')\n",
    "    plt.errorbar(epochs, val_loss, yerr=val_err, fmt='-o', capsize=5, label='Validation Loss', color='orange', markerfacecolor='white')\n",
    "    plt.xlabel('Epoch', fontsize=14)\n",
    "    plt.ylabel('Loss', fontsize=14)\n",
    "    plt.title('Training and Validation Loss', fontsize=16)\n",
    "    plt.legend(fontsize=12)\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('loss_curve.png', dpi=300)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5c34b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"checkpoints/SegmentationTrainer_epoch_1.pth\"\n",
    "model = load_model_checkpoint(checkpoint_path, config)\n",
    "dataset = SegmentationDataset(config)\n",
    "visualise_model_inference(model, dataset, event_idx=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efae805d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d221299",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
